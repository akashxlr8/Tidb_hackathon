{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Utilities\n",
    "import openai\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "from geopy.geocoders import Nominatim\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting OpenAI Credential\n",
    "openai.api_version = \"2024-02-01\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_type = 'azure'\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Initialization\n",
    "azure_openai_client = openai.AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), \n",
    "    # api_version = get_secret('GprntAICTDevOpenAIVersion'), \n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Engineering\n",
    "prompt = '''\n",
    "Answer the following question.\n",
    "     you are traveling and outing guider bot.\n",
    "     Generate answer with bullet points with reasoning of it's good.\n",
    "\n",
    "      ---\n",
    "      QUESTION: \n",
    "      {query}\n",
    "      ---\n",
    "\n",
    "      Current Location and weather:\n",
    "      {user_location_weather}\n",
    "\n",
    "      ---\n",
    "      Conversation History:\n",
    "      {conversation_history}\n",
    "      ---\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prompt Engineering\n",
    "prompt_suggestion = '''\n",
    "give me follow up suggestive questions in python list according to last query, response and previous conversation and current location and weather.\n",
    "<Query>:{question}\n",
    "<response>:{response}\n",
    "<previous conversation>: \n",
    "{conversation_history}\n",
    "Current Location and weather:\n",
    "{user_location_weather}\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def suggestion(user_input,response,conversation_history, user_location_weather):\n",
    "\n",
    "    # complete_search = pair[0] + pair[1]\n",
    "    # docs = vector_store_obj.similarity_search(query=complete_search, k=8, search_type='similarity')\n",
    "    \n",
    "    # Send prompt to LLM\n",
    "    data = azure_openai_client.chat.completions.create(\n",
    "        model=\"gpt-4\", \n",
    "        max_tokens=300, \n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You\\'re a Greenprint QnA Assistant'}, \n",
    "            {'role': 'user', 'content': prompt_suggestion.format(question=user_input, response=response, conversation_history=conversation_history, user_location_weather=user_location_weather)}\n",
    "        ], \n",
    "        stream=False\n",
    "    )\n",
    "    \n",
    "    return data.choices[0].message.content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_and_weather(latitude, longitude):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    \n",
    "    city = address.get('city', '')\n",
    "    state = address.get('state', '')\n",
    "    country = address.get('country', '')\n",
    "    postcode = address.get('postcode', '')\n",
    "\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}Â¤t_weather=true\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'current_weather' in data:\n",
    "        current_weather = data['current_weather']\n",
    "        temp = current_weather['temperature']\n",
    "        windspeed = current_weather['windspeed']\n",
    "        winddirection = current_weather['winddirection']\n",
    "        weathercode = current_weather['weathercode']\n",
    "        \n",
    "        return {\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"country\": country,\n",
    "            \"postcode\": postcode,\n",
    "            \"temperature\": temp,\n",
    "            \"windspeed\": windspeed,\n",
    "            \"winddirection\": winddirection,\n",
    "            \"weathercode\": weathercode\n",
    "        }\n",
    "    else:\n",
    "        return {\"error\": data.get(\"reason\", \"Failed to fetch weather data\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bot():\n",
    "    \n",
    "    # Initialize conversation history\n",
    "    conversation_history = []\n",
    "    # reference_time = datetime.datetime.now()\n",
    "\n",
    "    while True:\n",
    "            \n",
    "            # current_time = datetime.datetime.now()\n",
    "            # time_difference = current_time - reference_time\n",
    "            # time_difference_minutes = time_difference.total_seconds() / 60  # Convert seconds to minutes\n",
    "            # if time_difference_minutes < 1:\n",
    "                    # Get user input\n",
    "                user_input = input(\"You: \")\n",
    "\n",
    "                if user_input==\"e\" or user_input==\"stop\":\n",
    "                    break\n",
    "\n",
    "                print(\"Question: \",user_input)\n",
    "                # print(\"\\n\")\n",
    "                # docs = vector_store_obj.similarity_search(query=user_input, k=8, search_type='similarity')\n",
    "\n",
    "                # Calculate total token length of prompt\n",
    "                prompt_token_length = sum(len(chunk[\"content\"].split()) for chunk in conversation_history)\n",
    "                prompt_token_length += len(user_input) + 300\n",
    "                # print(conversation_history)\n",
    "                # If prompt token length exceeds 8000, remove conversations from the beginning\n",
    "                while prompt_token_length > 8000:\n",
    "                    removed_chunk = conversation_history.pop(0)\n",
    "                    prompt_token_length -= len(removed_chunk[\"content\"].split())\n",
    "\n",
    "                # Send prompt to LLM\n",
    "                data = azure_openai_client.chat.completions.create(\n",
    "                    model=\"gpt-4\", \n",
    "                    max_tokens=300, \n",
    "                    temperature=0.0,\n",
    "                    messages=[\n",
    "                        {'role': 'system', 'content': 'You\\'re a QnA Assistant'}, \n",
    "                        {'role': 'user', 'content': prompt.format(query=user_input, conversation_history=conversation_history, user_location_weather=user_location_weather)}\n",
    "                    ], \n",
    "                    stream=True\n",
    "                )\n",
    "                # print(data.choices[0].message.content)\n",
    "                s=\"\"\n",
    "                print(\"Answer: \")\n",
    "                # Streaming Print\n",
    "                for chunk in data:\n",
    "                    try:\n",
    "                        if chunk.choices[-1].delta.content != None:\n",
    "                            print(chunk.choices[-1].delta.content, end='')\n",
    "                            if not None:\n",
    "                                s += chunk.choices[-1].delta.content\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "\n",
    "                \n",
    "                # Update conversation history\n",
    "                conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "                conversation_history.append({\"role\": \"system\", \"content\": s})\n",
    "                suggestions=suggestion(user_input,s,conversation_history, user_location_weather)\n",
    "                print(\"\\n\")\n",
    "                print(\"Suggestion : \")\n",
    "                print(suggestions)\n",
    "\n",
    "                print(\"\\n\")\n",
    "                # Define a reference time\n",
    "                # reference_time = datetime.datetime.now()\n",
    "\n",
    "                    \n",
    "                # Limit conversation history size (optional)\n",
    "                # conversation_history = conversation_history[-10:] \n",
    "\n",
    "            # else:\n",
    "            #     flag=input(\"would you want to continue(yes/no): \")\n",
    "            #     if flag==\"yes\":\n",
    "            #         current_time = datetime.datetime.now()\n",
    "\n",
    "            #     else:\n",
    "            #         break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
